---
title: "Happiness Worldwide Reports by Gallup Group"
author: "Kristina Z"
date: "3/2/2021"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
---

# INTRODUCTION

## About

***DATASETS: 2015-2019 KAGGLE***

**Happiness Worldwide Report je kreirala istrazivacko-savetodavna
kompanija iz New York-a, SAD - GALLUP WORLD POLL LTD** **Prvi Report je
objavljen 2012. godine, u skladu sa Butanskom Rezolucijom koju je
prihvatila Generalna Skupstina *UN 2011*. godine kojom je pozvala
nacionalne vlade da daju veci znacaj sreci i blagostanju kod merenja
socijalnog i ekonomskog razvoja.** **Prvi Izvestaj je formiran u
saradnji Kolumbija Univerziteta iz Njujorka sa Kanadskim institutom za
napredna istrazivanja, a potom od 2013 godine je baziran na SDSN
(Sustainable Development Solutions Network) i Center for Sutainable
Develpoment Columbia Univerziteta.** **Bez obzira, osnovni izvor za
kreiranje izvestaja cine upitnici koje kreira Gallup Grupa, primenjujuci
"Cantril Ladder" sistem.**

**Izuzimajuci sadrzinu upitnika na osnovu kog se procenjuje da li je
jedan narod srecniji od drugog, a na osnovu datog dataseta podataka i
ovog pristupa proceni srece, mozemo zakljuciti da je narod u zemljama sa
boljim skorom srecniji od drugog, koji ima manji score. Na sam score i
rangiranje zemalja utice nekoliko faktora i kroz navedeni dataset cemo
videti koji faktori najvise uticu na score, odnosno srecu jednog
naroda**

# READ THE DATASETS

```{r}
df <- read.csv("2015.csv") 
df1 <- read.csv("2016.csv") 
df2 <- read.csv("2017.csv") 
df3 <- read.csv("2018.csv") 
df4 <-read.csv("2019.csv")



```

# MAIN FEATURES

```{r}
head(df1) 
colnames(df1) 
colnames(df2) 
colnames(df3) 
colnames(df4)

```

```{r}
colnames(df4)




```

```{r}
colnames(df3)

```

```{r}
colnames(df2)

```

```{r}
colnames(df1)

```

```{r}
colnames(df)

```

### INSTALACIJA NEOPHODNIH PAKETA

```{r include=FALSE}
#install.packages('dplyr') 
#install.packages('tidyverse') 
#install.packages('ggplot2')

```

## IMPLEMENTACIJA PAKETA

```{r}
library('dplyr') 
library('tidyverse') 
library('ggplot2')

```

# EDA

View the structure of data, rename or drop some columns, in order to
join them into one, adding column YEAR in each dataset

```{r}
dim(df) 
dim(df1) 
dim(df2) 
dim(df3) 
dim((df4)) 
colnames(df) 


```




#### cleaning the data

```{r}


colnames(df)
df <- df %>% rename(c("Rank" = "Happiness.Rank" ,              
                      "Score" = "Happiness.Score",
                      "GDP" = "Economy..GDP.per.Capita.",  
                      "Health" = "Health..Life.Expectancy.",     
                      "Corruption" = "Trust..Government.Corruption."))

```

```{r echo=TRUE}

colnames(df)



```

#### erase uneccessary columns
```{r}

df <- df[, -c(2,5,12)]

```


##### checking columns

```{r}
colnames(df)


```

#### change of columns place's

```{r}

df<-df[,c(2,1,3,4,5,6,7,9,8)] 

```

#### checking code

```{r}

colnames(df)

```

#### dataset 2016 cleaning 

```{r}

colnames(df1)

```

#### cleaning data

```{r}


df1 <- df1 %>% rename(c("Rank" = "Happiness.Rank" ,              
                        "Score" = "Happiness.Score",
                        "GDP" = "Economy..GDP.per.Capita.",  
                        "Health" = "Health..Life.Expectancy.",     
                        "Corruption" = "Trust..Government.Corruption.",
                        "Dystopia Residual" = "Dystopia.Residual"))   
colnames(df1)



```

#### drop unneccessary columns

```{r}

df1 <- df1[, -c(2,5,6,13)]
colnames(df1)

```

#### raspored kolona

```{r}
df1<-df1[,c(2,1,3,4,5,6,7,9,8)] 
colnames(df1)

```

### dataset 2017

```{r}

colnames(df2)



```

```{r}

df2 <- df2 %>% rename(c("Rank" = "Happiness.Rank" ,              
                         "Score" = "Happiness.Score",
                         "GDP" = "Economy..GDP.per.Capita.",  
                         "Health" = "Health..Life.Expectancy.",     
                         "Corruption" = "Trust..Government.Corruption.",
                         "Dystopia Residual" = "Dystopia.Residual"))       
colnames(df2)

```

#### drop unnneccessary columns

```{r}
df2 <- df2[, -c(4,5,12)]
colnames(df2)

```


#### changing place of columns

```{r}

df2<-df2[,c(2,1,3,4,5,6,7,8,9)]
colnames(df2)

```


#### dataset 2018

```{r}
colnames(df3)


```



```{r}
colnames(df3)
df3 <- df3 %>% rename(c("Rank"   = "Overall.rank",
                        "Country"= "Country.or.region",
                        "Score"  = "Score",
                        "GDP"    = "GDP.per.capita",
                        "Family" = "Social.support",
                        "Health" = "Healthy.life.expectancy",     
                        "Freedom"= "Freedom.to.make.life.choices",
                        "Corruption"= "Perceptions.of.corruption"))
colnames(df3)  


```

#### dataset df4

```{r}
colnames(df4)

```

#### cleaning data

```{r}

df4 <- df4 %>% rename(c("Rank"   = "Overall.rank",
                        "Country"= "Country.or.region",
                        "Score"  = "Score",
                        "GDP"    = "GDP.per.capita",
                        "Family" = "Social.support",
                        "Health" = "Healthy.life.expectancy",     
                        "Freedom"= "Freedom.to.make.life.choices",
                        "Corruption"= "Perceptions.of.corruption"))
colnames(df4)


```


### adding a year to datsets

```{r echo=TRUE}

df <- df %>% mutate(Year = 2015) 
df1 <- df1 %>% mutate(Year = 2016)
df2 <- df2 %>% mutate(Year = 2017)
df3 <- df3 %>% mutate(Year = 2018) 
df4 <- df4 %>% mutate(Year =2019) 


```

#####checking

```{r}
head(df)
head(df1)
head(df2)
head(df3)
```


### MERGE OF DATASETS

```{r}

df_all<-rbind(df,df1,df2,df3,df4) 
head(df_all)





```

#### checking

```{r}
tail(df_all)
head(df_all)
```



#### checking NA and NULL values

```{r}



is.na(df_all) 
is.na(df_all$Corruption) 
sum(is.na(df_all$Corruption))
sum(is.na(df_all))



df_all$Corruption <- as.numeric(df_all$Corruption)
sum(is.na(df_all$Corruption)) 
df_all$Corruption[is.na(df_all$Corruption)]<- median(df_all$Corruption) 
any(is.na(df_all$Corruption))
sum(is.na(df_all$Corruption)) 
df_all$Corruption[is.na(df_all$Corruption)]<- mean(df_all$Corruption) 
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)] <- mean(df_all$Corruption, na.rm = TRUE) 
sum(is.na(df_all$Corruption))
df_all$Country <- as.numeric(as.factor(df_all$Country))

str(df_all)






```

# CORRELATION BETWEEN VARIABLES

```{r}


cor <- cor(df_all) 
colnames(df_all) 
head(df_all) 
summary(df_all)


```

# LINEAR REGRESSION, RANDOM FOREST AND DECISION TREE

## LINEAR REGRESSION MODEL

```{r eval=FALSE, include=FALSE}
install.packages('rpart') 


```

```{r}
library(rpart) 
str(df_all)

# import libraries za vizuelizaciju da bi videli korelacije izmedju varijabli

library(ggplot2) 
library(ggthemes) 
num.cols <- sapply(df_all,is.numeric) 
cor.data <- cor(df_all[,num.cols]) 
print(cor.data)

#za vizuelizaciju importujemo corrgram i corplot pakete

#install.packages("corrgram") 
#install.packages("corrplot")
library(corrgram) 
library(corrplot)

print(corrplot(cor.data, method = 'color')) 
corrgram(df_all)

help("corrgram") 
corrgram(df_all, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie, text.panel = panel.txt)
ggplot(df_all,aes(x=Score)) + geom_histogram(bins =
20,alpha=0.5,fill='blue') 
ggplot(df_all,aes(x=GDP)) + geom_histogram(bins = 20,alpha=0.5,fill='blue')

#splitting the data into training and testing sets in order to apply ML model

#install.packages('caTools') 
library(caTools) 
set.seed(101)

#split up sample

sample <- sample.split(df_all$Score,SplitRatio = 0.7)

#70% data na trening, a 30% je test

train <- subset(df_all, sample==TRUE) 
test <- subset(df_all, sample==FALSE)

#LINEAR REGGRESSION MODEL U R: #model \<- lm(y\~x1+x2, data)

#TRAIN AND BUILD A MODEL

model <- lm(Score ~ .,train)



#RUN THE MODEL

#INTERPRET THE MODEL 
print(summary(model))


```

```{r}

res <- residuals(model) 

class(res)



```

#### PREDICTIONS

```{r}
Score.predictions <- predict(model, test)

results <-cbind(Score.predictions,test$Score) 

colnames(results)<-c('predicted','actual') 

results<-as.data.frame(results)

print(head(results))



```

##### taking care of negative values

```{r}
to_zero<- function(x) { 

if (x <0){ return(0) }else{ return(x) } }



```

##### APPLY ZERO FUNCTION

```{r}

results$predicted<-sapply(results$predicted,to_zero)

min(results)



```

#### MSE

```{r}
mse <- mean( (results$actual - results$predicted)^2) 
print("MSE") 
print(mse)


```

#### RMSE

```{r}
print("RMSE") 

print(mse^0.5)



```

#### SSE SST R2

```{r}
SSE <- sum( (results$predicted-results$actual)^2) 

SST <- sum((mean(df_all$Score)-results$actual)^2)

R2 <- 1- SSE/SST 
print('R2') 
print(R2)



```

# DECISION TREE

```{r}

library(rpart)

#splitting the data into training and testing sets in order to deploy ML model 

library(caTools) 

set.seed(101)

#split up sample

sample_dt <- sample.split(df_all$Score,SplitRatio = 0.7)

#70% data na trening, a 30% je test

train_dt <- subset(df_all, sample==TRUE) 

test_dt <- subset(df_all, sample==FALSE)

str(df_all) 

tree <- rpart(Score~.,method = 'anova',train_dt) 

printcp(tree)



```

#### INTERPRET THE MODEL

```{r}

print(summary(tree))

res_dt <- residuals(tree) 

class(res_dt)



```

#### PREDICTIONS

```{r}

Score.predictions_dt <- predict(tree, test_dt)

results_dt <-cbind(Score.predictions_dt,test_dt$Score) 

colnames(results_dt) <-c('predicted','actual') 

results_dt<-as.data.frame(results_dt)

print(head(results_dt))





```

#### MSE

```{r}

mse_dt <- mean( (results_dt$actual - results_dt$predicted)^2) 

print("MSE DECISION TREE") 

print(mse_dt)



```

#### RMSE

```{r}

print("RMSE") 

print(mse_dt^0.5)

#install.packages('rpart.plot') 

library(rpart.plot) 

prp(tree) 

rsq.rpart(tree) 

summary(tree)



```

# RANDOM FOREST MODEL

```{r}

#install.packages('randomForest') 

library(randomForest)

#splitting the data into training and testing sets in order to deploy ML model 

library(caTools) 

set.seed(101)

#split up sample

sample_rf <- sample.split(df_all$Score,SplitRatio = 0.7)

#70% data na trening, a 30% je test

train_rf <- subset(df_all, sample==TRUE) 

test_rf <- subset(df_all, sample==FALSE)

rf.model <- randomForest(Score~.,train_rf)

```

#### INTERPRET THE RESULTS

```{r}

print(summary(rf.model))

res_rf <- residuals(rf.model) 

class(res_rf)



```

#### PREDICTIONS

```{r}

Score.predictions_rf <- predict(rf.model, test_rf)

results_rf <-cbind(Score.predictions_rf,test$Score) 

colnames(results_rf) <-c('predicted','actual') 

results_rf<-as.data.frame(results_rf)

print(head(results_rf))



```

#### MSE

```{r}

mse_rf <- mean( (results_rf$actual - results_rf$predicted)^2) 

print("MSE RANDOM FOREST") 

print(mse_rf)





```

#### RMSE

```{r}

print("RMSE RANDOM FOREST") 

print(mse_rf^0.5)

print(rf.model) 
rf.model$ntree 
rf.model$mse 
rf.model$rsq

rf.model$predicted 
rf.model$type 
rf.model$oob.times 
rf.model$proximity 
rf.model$summary 
summary(rf.model$train_rf) 
summary(rf.model$test_rf)

```
