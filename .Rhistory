df_all$Corruption[is.na(df_all$Corruption)]<- median(df_all$Corruption)
any(is.na(df_all$Corruption))
sum(is.na(df_all$Corruption)) df_all$Corruption[is.na(df_all\$Corruption)]<- mean(df_all$Corruption) sum(is.na(df_all$Corruption))
is.na(df_all)
is.na(df_all$Corruption)
sum(is.na(df_all$Corruption))
sum(is.na(df_all))
df_all$Corruption <- as.numeric(df_all$Corruption)
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)]<- median(df_all$Corruption)
any(is.na(df_all$Corruption))
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all\$Corruption)]<- mean(df_all$Corruption)
is.na(df_all)
is.na(df_all$Corruption)
sum(is.na(df_all$Corruption))
sum(is.na(df_all))
df_all$Corruption <- as.numeric(df_all$Corruption)
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)]<- median(df_all$Corruption)
any(is.na(df_all$Corruption))
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)]<- mean(df_all$Corruption)
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)] <- mean(df_all$Corruption, na.rm = TRUE)
sum(is.na(df_all$Corruption))
df_all$Country <- as.numeric(as.factor(df_all$Country))
str(df_all)
cor <- cor(df_all)
colnames(df_all)
head(df_all)
summary(df_all)
install.packages('rpart')
install.packages("rpart")
library(rpart)
str(df_all)
# import libraries za vizuelizaciju da bi videli korelacije izmedju varijabli
library(ggplot2)
library(ggthemes)
num.cols <- sapply(df_all,is.numeric)
cor.data <- cor(df_all[,num.cols])
print(cor.data)
#za vizuelizaciju importujemo corrgram i corplot pakete
install.packages("corrgram")
install.packages("corrplot")
library(corrgram)
library(corrplot)
print(corrplot(cor.data, method = 'color'))
corrgram(df_all)
help("corrgram")
corrgram(df_all, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie, text.panel = panel.txt)
ggplot(df_all,aes(x=Score)) + geom_histogram(bins =
20,alpha=0.5,fill='blue')
ggplot(df_all,aes(x=GDP)) + geom_histogram(bins = 20,alpha=0.5,fill='blue')
#splitting the data into training and testing sets in order to apply ML model
install.packages('caTools')
library(caTools)
set.seed(101)
#split up sample
sample <- sample.split(df_all$Score,SplitRatio = 0.7)
#70% data na trening, a 30% je test
train <- subset(df_all, sample==TRUE)
test <- subset(df_all, sample==FALSE)
#LINEAR REGGRESSION MODEL U R: #model \<- lm(y\~x1+x2, data)
#TRAIN AND BUILD A MODEL
model <- lm(Score ~ .,train)
#RUN THE MODEL
#INTERPRET THE MODEL
print(summary(model))
res <- residuals(model)
class(res)
Score.predictions <- predict(model, test)
results <-cbind(Score.predictions,test$Score)
colnames(results)<-c('predicted','actual')
results<-as.data.frame(results)
print(head(results))
to_zero<- function(x) {
if (x <0){ return(0) }else{ return(x) } }
results$predicted<-sapply(results$predicted,to_zero)
min(results)
mse <- mean( (results$actual - results$predicted)^2)
print("MSE")
print(mse)
print("RMSE")
print(mse^0.5)
SSE <- sum( (results$predicted-results$actual)^2)
SST <- sum((mean(df_all$Score)-results$actual)^2)
R2 <- 1- SSE/SST
print('R2')
print(R2)
library(rpart)
#splitting the data into training and testing sets in order to deploy ML model
library(caTools)
set.seed(101)
#split up sample
sample_dt <- sample.split(df_all$Score,SplitRatio = 0.7)
#70% data na trening, a 30% je test
train_dt <- subset(df_all, sample==TRUE)
test_dt <- subset(df_all, sample==FALSE)
str(df_all)
tree <- rpart(Score~.,method = 'anova',train_dt)
printcp(tree)
print(summary(tree))
res_dt <- residuals(tree)
class(res_dt)
Score.predictions_dt <- predict(tree, test_dt)
results_dt <-cbind(Score.predictions_dt,test_dt$Score)
colnames(results_dt) <-c('predicted','actual')
results_dt<-as.data.frame(results_dt)
print(head(results_dt))
colnames(df4)
colnames(df3)
colnames(df2)
colnames(df1)
colnames(df)
dim(df)
dim(df1)
dim(df2)
dim(df3)
dim((df4))
colnames(df)
colnames(df2)
df2 <- df2 %>% rename(c("Happiness Rank" = "Happiness.Rank" ,
"Happiness Score" = "Happiness.Score",
"Economy (GDP per Capita)" = "Economy..GDP.per.Capita.",
"Health (Life Expectancy)" = "Health..Life.Expectancy.",
"Trust (Government Corruption)" = "Trust..Government.Corruption.",
"Dystopia Residual" = "Dystopia.Residual"))
colnames(df)
df <- df %>% rename(c("Rank" = "Happiness.Rank" ,
"Score" = "Happiness.Score",
"GDP" = "Economy..GDP.per.Capita.",
"Health" = "Health..Life.Expectancy.",
"Corruption" = "Trust..Government.Corruption."))
colnames(df2)
df2 <- df2 %>% rename(c("Rank" = "Happiness Rank" ,
"Score" = "Happiness Score",
"GDP" = "Economy (GDP per Capita)",
"Health" = "Health (Life Expectancy)",
"Corruption" = "Trust (Government Corruption)"))
head(df2)
df2 <- df2[, -c(4,5,12)]
colnames(df2)
colnames(df)
colnames(df1)
df1 <- df1 %>% rename(c("Rank" = "Happiness.Rank" ,
"Score" = "Happiness.Score",
"GDP" = "Economy..GDP.per.Capita.",
"Health" = "Health..Life.Expectancy.",
"Corruption" = "Trust..Government.Corruption.",
"Dystopia Residual" = "Dystopia.Residual"))
colnames(df1)
df1 <- df1[, -c(2,5,6,13)]
colnames(df1)
colnames(df3)
df3 <- df3 %>% rename(c("Rank"   = "Overall.rank",
"Country"= "Country.or.region",
"Score"  = "Score",
"GDP"    = "GDP.per.capita",
"Family" = "Social.support",
"Health" = "Healthy.life.expectancy",
"Freedom"= "Freedom.to.make.life.choices",
"Corruption"= "Perceptions.of.corruption"))
colnames(df3)
colnames(df4)
df4 <- df4 %>% rename(c("Rank"   = "Overall.rank",
"Country"= "Country.or.region",
"Score"  = "Score",
"GDP"    = "GDP.per.capita",
"Family" = "Social.support",
"Health" = "Healthy.life.expectancy",
"Freedom"= "Freedom.to.make.life.choices",
"Corruption"= "Perceptions.of.corruption"))
colnames(df4)
# Chunk 1
df <- read.csv("2015.csv")
df1 <- read.csv("2016.csv")
df2 <- read.csv("2017.csv")
df3 <- read.csv("2018.csv")
df4 <-read.csv("2019.csv")
# Chunk 2
head(df1)
colnames(df1)
colnames(df2)
colnames(df3)
colnames(df4)
# Chunk 3
colnames(df4)
# Chunk 4
colnames(df3)
# Chunk 5
colnames(df2)
# Chunk 6
colnames(df1)
# Chunk 7
colnames(df)
# Chunk 8
#install.packages('dplyr')
#install.packages('tidyverse')
#install.packages('ggplot2')
# Chunk 9
library('dplyr')
library('tidyverse')
library('ggplot2')
# Chunk 10
dim(df)
dim(df1)
dim(df2)
dim(df3)
dim((df4))
colnames(df)
# Chunk 1
df <- read.csv("2015.csv")
df1 <- read.csv("2016.csv")
df2 <- read.csv("2017.csv")
df3 <- read.csv("2018.csv")
df4 <-read.csv("2019.csv")
# Chunk 2
head(df1)
colnames(df1)
colnames(df2)
colnames(df3)
colnames(df4)
# Chunk 3
colnames(df4)
# Chunk 4
colnames(df3)
# Chunk 5
colnames(df2)
# Chunk 6
colnames(df1)
# Chunk 7
colnames(df)
# Chunk 8
#install.packages('dplyr')
#install.packages('tidyverse')
#install.packages('ggplot2')
# Chunk 9
library('dplyr')
library('tidyverse')
library('ggplot2')
# Chunk 10
dim(df)
dim(df1)
dim(df2)
dim(df3)
dim((df4))
colnames(df)
colnames(df)
df <- df %>% rename(c("Rank" = "Happiness.Rank" ,
"Score" = "Happiness.Score",
"GDP" = "Economy..GDP.per.Capita.",
"Health" = "Health..Life.Expectancy.",
"Corruption" = "Trust..Government.Corruption."))
df <- read.csv("2015.csv")
df1 <- read.csv("2016.csv")
df2 <- read.csv("2017.csv")
df3 <- read.csv("2018.csv")
df4 <-read.csv("2019.csv")
head(df1)
colnames(df1)
colnames(df2)
colnames(df3)
colnames(df4)
colnames(df4)
colnames(df3)
colnames(df2)
colnames(df1)
colnames(df)
#install.packages('dplyr')
#install.packages('tidyverse')
#install.packages('ggplot2')
library('dplyr')
library('tidyverse')
library('ggplot2')
library('dplyr')
library('tidyverse')
library('ggplot2')
dim(df)
dim(df1)
dim(df2)
dim(df3)
dim((df4))
colnames(df)
#### cleaning the data
df <- df %>% rename(c("Rank" = "Happiness.Rank" ,
"Score" = "Happiness.Score",
"GDP" = "Economy..GDP.per.Capita.",
"Health" = "Health..Life.Expectancy.",
"Corruption" = "Trust..Government.Corruption."))
colnames(df)
df <- df[, -c(2,5,12)]
colnames(df)
#### change of columns place's
df<-df[,c(2,1,3,4,5,6,7,9,8)]
#### checking code
colnames(df)
#### dataset 2016 cleaning
#### dataset 2016 cleaning
colnames(df1)
df1 <- df1 %>% rename(c("Rank" = "Happiness.Rank" ,
"Score" = "Happiness.Score",
"GDP" = "Economy..GDP.per.Capita.",
"Health" = "Health..Life.Expectancy.",
"Corruption" = "Trust..Government.Corruption.",
"Dystopia Residual" = "Dystopia.Residual"))
colnames(df1)
#### drop unneccessary columns
colnames(df1)
df1 <- df1[, -c(2,5,6,13)]
colnames(df1)
#### raspored kolona
df1<-df1[,c(2,1,3,4,5,6,7,9,8)]
colnames(df1)
colnames(df2)
df2 <- df2 %>% rename(c("Rank" = "Happiness.Rank" ,
"Score" = "Happiness.Score",
"GDP" = "Economy..GDP.per.Capita.",
"Health" = "Health..Life.Expectancy.",
"Corruption" = "Trust..Government.Corruption.",
"Dystopia Residual" = "Dystopia.Residual"))
colnames(df2)
df2 <- df2[, -c(4,5,12)]
colnames(df2)
df2<-df2[,c(2,1,3,4,5,6,7,8,9)]
colnames(df2)
colnames(df3)
colnames(df3)
df3 <- df3 %>% rename(c("Rank"   = "Overall.rank",
"Country"= "Country.or.region",
"Score"  = "Score",
"GDP"    = "GDP.per.capita",
"Family" = "Social.support",
"Health" = "Healthy.life.expectancy",
"Freedom"= "Freedom.to.make.life.choices",
"Corruption"= "Perceptions.of.corruption"))
colnames(df3)
colnames(df4)
df4 <- df4 %>% rename(c("Rank"   = "Overall.rank",
"Country"= "Country.or.region",
"Score"  = "Score",
"GDP"    = "GDP.per.capita",
"Family" = "Social.support",
"Health" = "Healthy.life.expectancy",
"Freedom"= "Freedom.to.make.life.choices",
"Corruption"= "Perceptions.of.corruption"))
colnames(df4)
df_all<-rbind(df,df1,df2,df3,df4)
head(df_all)
df <- df %>% mutate(Year = 2015)
df1 <- df1 %>% mutate(Year = 2016)
df2 <- df2 %>% mutate(Year = 2017)
df3 <- df3 %>% mutate(Year = 2018)
df4 <- df4 %>% mutate(Year =2019)
head(df)
head(df1)
head(df2)
head(df3)
df_all<-rbind(df,df1,df2,df3,df4)
head(df_all)
tail(df_all)
head(df_all)
is.na(df_all)
is.na(df_all$Corruption)
sum(is.na(df_all$Corruption))
sum(is.na(df_all))
df_all$Corruption <- as.numeric(df_all$Corruption)
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)]<- median(df_all$Corruption)
any(is.na(df_all$Corruption))
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)]<- mean(df_all$Corruption)
sum(is.na(df_all$Corruption))
df_all$Corruption[is.na(df_all$Corruption)] <- mean(df_all$Corruption, na.rm = TRUE)
sum(is.na(df_all$Corruption))
df_all$Country <- as.numeric(as.factor(df_all$Country))
str(df_all)
cor <- cor(df_all)
colnames(df_all)
head(df_all)
summary(df_all)
install.packages('rpart')
install.packages("rpart")
library(rpart)
str(df_all)
# import libraries za vizuelizaciju da bi videli korelacije izmedju varijabli
library(ggplot2)
library(ggthemes)
num.cols <- sapply(df_all,is.numeric)
cor.data <- cor(df_all[,num.cols])
print(cor.data)
#za vizuelizaciju importujemo corrgram i corplot pakete
install.packages("corrgram")
install.packages("corrplot")
library(corrgram)
library(corrplot)
print(corrplot(cor.data, method = 'color'))
corrgram(df_all)
help("corrgram")
corrgram(df_all, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie, text.panel = panel.txt)
ggplot(df_all,aes(x=Score)) + geom_histogram(bins =
20,alpha=0.5,fill='blue')
ggplot(df_all,aes(x=GDP)) + geom_histogram(bins = 20,alpha=0.5,fill='blue')
#splitting the data into training and testing sets in order to apply ML model
install.packages('caTools')
library(caTools)
set.seed(101)
#split up sample
sample <- sample.split(df_all$Score,SplitRatio = 0.7)
#70% data na trening, a 30% je test
train <- subset(df_all, sample==TRUE)
test <- subset(df_all, sample==FALSE)
#LINEAR REGGRESSION MODEL U R: #model \<- lm(y\~x1+x2, data)
#TRAIN AND BUILD A MODEL
model <- lm(Score ~ .,train)
#RUN THE MODEL
#INTERPRET THE MODEL
print(summary(model))
res <- residuals(model)
class(res)
Score.predictions <- predict(model, test)
results <-cbind(Score.predictions,test$Score)
colnames(results)<-c('predicted','actual')
results<-as.data.frame(results)
print(head(results))
to_zero<- function(x) {
if (x <0){ return(0) }else{ return(x) } }
results$predicted<-sapply(results$predicted,to_zero)
min(results)
mse <- mean( (results$actual - results$predicted)^2)
print("MSE")
print(mse)
print("RMSE")
print(mse^0.5)
SSE <- sum( (results$predicted-results$actual)^2)
SST <- sum((mean(df_all$Score)-results$actual)^2)
R2 <- 1- SSE/SST
print('R2')
print(R2)
library(rpart)
#splitting the data into training and testing sets in order to deploy ML model
library(caTools)
set.seed(101)
#split up sample
sample_dt <- sample.split(df_all$Score,SplitRatio = 0.7)
#70% data na trening, a 30% je test
train_dt <- subset(df_all, sample==TRUE)
test_dt <- subset(df_all, sample==FALSE)
str(df_all)
tree <- rpart(Score~.,method = 'anova',train_dt)
printcp(tree)
print(summary(tree))
res_dt <- residuals(tree)
class(res_dt)
print(summary(tree))
res_dt <- residuals(tree)
class(res_dt)
Score.predictions_dt <- predict(tree, test_dt)
results_dt <-cbind(Score.predictions_dt,test_dt$Score)
colnames(results_dt) <-c('predicted','actual')
results_dt<-as.data.frame(results_dt)
print(head(results_dt))
mse_dt <- mean( (results_dt$actual - results_dt$predicted)^2)
print("MSE DECISION TREE")
print(mse_dt)
print("RMSE")
print(mse_dt^0.5)
install.packages('rpart.plot')
library(rpart.plot)
prp(tree)
rsq.rpart(tree)
summary(tree)
install.packages('randomForest')
library(randomForest)
#splitting the data into training and testing sets in order to deploy ML model
library(caTools)
set.seed(101)
#split up sample
sample_rf <- sample.split(df_all$Score,SplitRatio = 0.7)
#70% data na trening, a 30% je test
train_rf <- subset(df_all, sample==TRUE)
test_rf <- subset(df_all, sample==FALSE)
rf.model <- randomForest(Score~.,train_rf)
print(summary(rf.model))
res_rf <- residuals(rf.model)
class(res_rf)
Score.predictions_rf <- predict(rf.model, test_rf)
results_rf <-cbind(Score.predictions_rf,test$Score)
colnames(results_rf) <-c('predicted','actual')
results_rf<-as.data.frame(results_rf)
print(head(results))
Score.predictions_rf <- predict(rf.model, test_rf)
results_rf <-cbind(Score.predictions_rf,test$Score)
colnames(results_rf) <-c('predicted','actual')
results_rf<-as.data.frame(results_rf)
print(head(results_rf))
mse_rf <- mean( (results_rf$actual - results_rf$predicted)^2)
print("MSE RANDOM FOREST")
print(mse_rf)
print("RMSE RANDOM FOREST")
print(mse_rf^0.5)
print(rf.model)
rf.model$ntree
rf.model$mse
rf.model$rsq
rf.model$predicted
rf.model$type
rf.model$oob.times
rf.model$proximity
rf.model$summary
summary(rf.model$train_rf)
summary(rf.model$test_rf)
